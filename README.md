# Mohamed Ahsan M J ğŸ‘‹

AWS Certified | Cloud Data Engineer | Spark & Delta Lake  
Designing and implementing scalable batch data pipelines using AWS and distributed data processing frameworks.

---

## ğŸ‘¨â€ğŸ’» Professional Summary

Cloud-focused Data Engineer with hands-on experience building end-to-end data lake architectures using AWS, Apache Spark, and Delta Lake.

Experienced in designing medallion architectures, implementing incremental and idempotent processing, enforcing schema validation, and developing production-oriented data workflows.

---

## ğŸš€ Core Competencies

- Batch Data Pipeline Design
- ETL / ELT Development
- Distributed Data Processing (Spark)
- Data Modeling (Star / Snowflake)
- Medallion Architecture (Bronze / Silver / Gold)
- ACID Data Lake Implementation
- Schema Enforcement & Evolution
- Incremental & Idempotent Processing
- Data Quality Validation
- Performance Optimization & Partitioning
- IAM-Based Access Control
- Version Control & CI/CD Fundamentals

---

## ğŸ› ï¸ Technical Stack

### Programming
- Python
- SQL

### Big Data & Processing
- Apache Spark
- PySpark
- Delta Lake
- Hive / HDFS

### Cloud Platform
- AWS (S3, Glue, Athena, EMR, Redshift, IAM, CloudWatch, KMS)
- Databricks (Notebooks, Unity Catalog)

### Databases
- Microsoft SQL Server
- MySQL

### Data Engineering Concepts
- Partitioning & Bucketing
- Full & Incremental Loads
- Change Data Capture (CDC)
- ACID Transactions in Data Lakes
- Metadata Management (Glue Data Catalog, Unity Catalog)
- Table, Row & Column-Level Access Policies
- OLAP & OLTP Systems

### Tools
- Git
- Docker
- Linux / Ubuntu
- VS Code

---

## ğŸ”­ Current Focus Areas

- Production-style end-to-end data lake implementations
- Scalable Spark transformation design
- Data validation and observability
- Performance tuning for large datasets
- Infrastructure-aware pipeline architecture

---

## ğŸ“‚ Featured Projects

### AWS Event-Driven Data Platform
Designed a medallion-based data lake pipeline using PySpark and Delta Lake with real-world malformed data handling.

Key Features:
- Bronze â†’ Silver â†’ Gold transformation layers
- Idempotent processing across layers
- Schema validation and enforcement
- Incremental ingestion strategy
- IAM-based access policies
- Partitioning for optimized query performance

ğŸ”— https://github.com/mjahsan/aws-event-driven-data-platform

---

### Commerce Data Processing Workflow
Built an ETL pipeline to ingest, validate, transform, and curate analytics-ready commerce data.

Key Features:
- Lakehouse architecture (Bronze / Silver / Gold)
- Modular Spark transformations
- Encryption using AWS KMS
- Structured logging and monitoring

ğŸ”— https://github.com/mjahsan/aws-etl-commerce-data-processing

---

## ğŸ“« Contact

Email: inboxofahsan@gmail.com  
LinkedIn: https://www.linkedin.com/in/mohamedahsanmj  
GitHub: https://github.com/mjahsan
